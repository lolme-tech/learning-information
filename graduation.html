<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Graduation thesis</title>
        <link rel="stylesheet" type="text/css" href="styles/graduation.css">
        <link href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" rel="stylesheet">
        <link rel="graduation" type="text/css" href="”https://lolme-tech.github.io/lerning-information/styles/graduation">
        <script src="//code.jquery.com/jquery-1.12.1.min.js"></script>
    </head>
    <body>
        <div class="header">
            <a href="index.html" class="head">HOME</a>
        </div>
        <div class="body">
            <h1 class="agenda">卒業論文について(2022年4月3日更新)</h1>
            <p class="desc">私の卒業論文の主なテーマは人工知能を用いた手の形状による個人認証に関する研究です。
                <br>個人認証には、指紋認証、顔認証、虹彩認証といった身体的特徴を用いた手法と、パスワードによる記憶認証や歩き方を
                <br>特徴とする歩行認証などの行動的特徴を用いた認証技術があります。
                <br>私の研究では、その中でも手の形状を用いた身体的特徴を用いて認証を行います。
                <br>従来の個人認証では、それぞれ人によって異なる特徴を幾何学的にデータベースに登録し、
                <br>それを照合したスコアによる差分を元に認証を行います。
                <br>しかしながら、私の研究では手の画像を機械学習させることで何が特徴として用いられるかがわからないことが大きく異なります。
                <br>人の手には、指紋や指の大きさ、手のサイズ、それによる影の落とし方など様々な特徴があり、
                <br>それを機械は写真というpx(ピクセル)としてのデータとして分析をします。
            </p>
            <h2 class="title">卒業研究の手順</h2>
            <p class="desc">まず手の画像を機械学習させるには、ある程度数を用意しなければ良い学習を行うことはできません。
                <br>そこで、スマホ用の三脚と間接照明を用意して白い画用紙を敷いた上に配置します。
                <br>白い画用紙に袖をまくった腕を載せて照明を当て、スマホで約5～7秒動画を撮影します。
                <br>こうすることで、PythonのopenCVというライブラリで動画からフレームレートを抽出し、
                <br>大量の画像を簡単に入手することが出来ます。
                <br>5秒間撮影したとしたら、スマホのフレームレートが30なので一人当たり約150枚手に入れることが出来ます。
                <br>動画を撮影する際は、ただ手を置くだけでなく、指を開く、閉じるを交互に繰り返すことで様々な形をした手の画像を入手します。
                <br>機械学習に関しては学び途中であり、本研究もどのような結果になるかわからないため、
                <br>模索しながら最適と感じる方法で準備を行いました。
                <br>手は表の手の平及び裏の手の平を撮影しました。下記に抽出したフレームレートの手の画像を示します。
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo12.jpg?raw=true" class="photos">
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo13.jpg?raw=true" class="photos">
                <br>この一人当たり表の手約150枚と裏の手約150枚の計300枚を沢山の人に協力してもらい画像を収集していきます。
                <br>機械学習には、2014年に画像認識を競う大会でVGGというチームが使用した畳み込みニューラルネットワークというものを用います。
                <br>この機械学習には、8割を学習モデルに、残りの2割を正解モデルとして用います。(正解モデルを用いているので教師あり学習)
                <br>畳み込みニューラルネットワークは畳み込み層とプーリング層に別れ、
                <br>特徴を見つけてそれを圧縮というのを繰り返すモデルになります。
                <br>下の図は、畳み込みニューラルネットワークの構造を表したものになります。
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo14.png?raw=true" class="photos1">
                <br>しかし、本研究ではあくまでも機械学習を用いた個人認証が目的なので、機械学習自体はただのツールとして用いたために
                <br>詳細に原理を理解しているわけではありません。
                <br>機械学習に収集した画像群を与えるために、numpyという二次元処理を簡単に行うPythonのライブラリを用いて、
                <br>ラベル(画像群にラベリング)と画像群の2次元配列にします。
                <br>例えば、ラベル0には自分の表の手の画像群150枚、ラベル1には自分の裏の手の画像群150枚という風に格納されます。
                <br>下の表は、numpy形式のファイルの中身を表しています。<br>
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo15.png?raw=true" class="photos2">
                <br>このnumpy形式のファイルを機械学習のモデルに与えます。
                <br>このラベルごとにはフレームレートから抽出した画像が格納されているので、すべて異なる画像が格納されています。
            </p>
            <h2 class="title">評価手順</h2>
            <p class="desc">
                学習モデルに先に述べたnumpy形式のファイルを与えたところで、出力される結果がないといけません。
                <br>そのため、本研究では手の画像を学習モデルに与えた際にこの手の画像は誰の手で表裏のどちらかを言い当てるように出力させる。
                <br>下記の画像は、テスト画像を与えた際の出力結果を表す。<br>
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo16.png?raw=true" class="photos">
                <br>この時、テスト画像として与えた画像が「江波戸の表の画像」なので、それを機械は100%の確率で言い当てていることが分かる。
                <br>テスト画像には、機械学習をする前に撮影した画像から目視で形状の異なる手の画像を表裏10枚ずつ抜き取っていき、
                <br>1人当たり計20枚のテスト画像を用意しておく。
                <br>下記の画像はそのテスト画像群のファイルの中身を表す。<br>
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo17.png?raw=true" class="photos3">
                <br>このテスト画像と出力結果をもとに撮影環境を変化させて評価を行っていく。
            </p>
            <h2 class="title">実験1の評価結果</h2>
            <p class="desc">機械学習させる画像群は、三脚と照明を用いて撮影を行い、テスト画像に与える画像はスマホを手で持ち
                <br>固定や照明を与えずに撮影したものを用いる。テスト画像を与える際の解像度は撮影時と変わらないものを用いる。
                <br>また、研究の初期段階であったためにテスト画像は表裏10枚ずつではなく、1枚ずつ与えた。
                <br>その際、機械学習をする時の解像度を縦×横64、128、256ピクセルと変化させて行うものとする。
                <br>その結果、64ピクセルの時、表の手を98%、裏の手を87%の確率で正確にテスト画像の手を識別できた。
                <br>128ピクセルの時、表の手を100%、裏の手を99%の確率で正確にテスト画像の手を識別できた。
                <br>128ピクセルの時、表の手を73%の確率で正確にテスト画像を識別し、裏の手を92%の確率でテスト画像とは別の人の手と識別し、
                <br>さらに裏の手ではなく表の手であると識別した。このことから解像度を上げすぎても下げすぎてもよくないことが分かる。
                <br>また、128ピクセルの解像度が最適であることが現状から察することができる。
                <br>下記の画像は、128ピクセルの時の出力結果を表す。<br>
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo18.png?raw=true" class="photos">
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo19.png?raw=true" class="photos">
                <br>テスト画像には他にも閉じている手や、半開きの手など形状の異なる画像を撮影し、128ピクセルの学習モデルに
                <br>計3枚与えた結果、高確率でテスト画像を正確に識別することが出来た。

            </p>
            <h2 class="title">実験2の評価結果</h2>
            <p class="desc">次に学習モデルに与える画像とテスト画像ともに三脚と照明を用いて撮影したものを用いて行う。
                <br>テスト画像には、学習する前に抜き取った表裏10枚ずつを用いる。
                <br>学習する際の縦×横の解像度は32、64、128、256ピクセルでそれぞれ行い、それにかかる学習時間も計測する。
                <br>その結果、学習に用いた時間は32ピクセルで48秒、64ピクセルで3分4秒、128ピクセルで13分21秒、
                <br>256ピクセルで53分18秒かかったことから、画像の解像度を撮影時の解像度に合わせようとすればするほど
                <br>学習に時間がかかることが言える。
                <br>撮影した人は全員で5人、全2064枚のうち8割の1651枚を学習させ残りの2割を正解モデルとして使用する。
                <br>テスト画像には、事前に抜き取った5人分の表裏計100枚の画像を用いる。
                <br>その結果、32、64、128ピクセルですべてのテスト画像に対して100%の確率で正確に識別できた。
                <br>256ピクセルでは、1枚だけ99%の確率で識別されたものの、それ以外はすべて100%の確率で識別できた。
                <br>このことから本研究は本人を正確に識別するいわゆる本人拒否率が非常に低いということが言える。
            </p>
            <h2 class="title">実験3の評価結果</h2>
            <p class="desc">次にこの学習モデルに対して学習していない人の手を与えた結果どうなるかを評価する。
                <br>これはいわゆる他人受入率に関する評価であり、15人の内6人分の手を学習させて、残りの9人の
                <br>画像を適当に学習モデルに与えた結果、低い確率で識別されるかを評価する。
                <br>その際に、出力される確率に閾値を設け、その閾値未満で識別した場合には、「認証できません」と出力されるように
                <br>プログラムを改変する。下記の画像は、学習していない人の手の画像を与えた際に閾値以下の確率であるために
                <br>「認証できません」と出力している出力結果を表す。<br>
                <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo20.png?raw=true" class="photos">
                <br>その際、9人分のテスト画像は実験2と同様に表裏20枚ずつの計180枚を用い、閾値は実験2で高い確率で識別されていたことから
                <br>99%未満、100%未満とする。また解像度は変化させずに128ピクセルで統一して行うものとする。
                <br>その結果、閾値99%未満の時、
                <br>・全体の正当な認証の割合:83/180=約46%
                <br>・全体の誤認証の割合:97/180=約54%<br>
                <br>・全体の表の手の正当な認証の割合:43/90=約48%
                <br>・全体の表の手の誤認証の割合:47/90=約52%<br>
                <br>・全体の裏の手の正当な認証の割合:40/90=約44%
                <br>・全体の裏の手の誤認証の割合:50/90=約56%<br>
                <br>という結果になった。ここで正当な認証とは低い確率で認証したことを指し、誤認証とは誤って閾値以上の確率で
                <br>未学習の9人のうちのテスト画像を識別してしまったことを表す。
                <br>次に閾値100%未満の時、
                <br>・全体の正当な認証の割合:165/180=約92%
                <br>・全体の誤認証の割合:15/180=約8%<br>
                <br>・全体の表の手の正当な認証の割合:83/90=約92%
                <br>・全体の表の手の誤認証の割合:7/90=約8%<br>
                <br>・全体の裏の手の正当な認証の割合:82/90=約91%
                <br>・全体の裏の手の誤認証の割合:8/90=約9%<br>
                <br>という結果になった。以上のことから閾値99%未満の時は2回に一回は他人を受け入れてしまい、
                <br>閾値100%未満の時は10ッ回に一回他人を受け入れてしまうということが分かる。
                <br>実際に皆さんの携帯で指紋認証や顔認証を行う際に友達が上記の確率で勝手に使用できてしまったら
                <br>とても実用的とは言えません。このことから、機械学習での認証システムは他人受入率をどのように改善するかが
                <br>今後の展望と言えます。
                </p>
            <h2 class="title">実験4の評価結果</h2>
            <p class="desc">次に学習用とテスト用どちらも三脚で固定して撮影はするものの、照明をありなしで
                <br>変化させて実験を行う。その結果から照明の有無による機械学習への影響を調べる。
                <br>また、実験に用いる人の手は5人分を用いるものとする。
                <br>まず初めに、照明ありで撮影した学習モデルに対して照明なしで撮影したテスト画像100枚を用いる。
                <br>その結果、
                <br>・全体の正当な認証の割合:23/100=23%
                <br>・全体の誤認証の割合:77/100=77%<br>
                <br>・全体の表の手の正当な認証の割合:12/50=24%
                <br>・全体の表の手の誤認証の割合:38/50=76%<br>
                <br>・全体の裏の手の正当な認証の割合:11/50=22%
                <br>・全体の裏の手の誤認証の割合:39/50=78%<br>
                <br>という結果となる。
                <br>次に照明なしで撮影した学習モデルに対して照明ありで撮影したテスト画像100枚を用いる。
                <br>その結果、
                <br>・全体の正当な認証の割合:40/100=40%
                <br>・全体の誤認証の割合:60/100=60%<br>
                <br>・全体の表の手の正当な認証の割合:18/50=36%
                <br>・全体の表の手の誤認証の割合:32/50=64%<br>
                <br>・全体の裏の手の正当な認証の割合:22/50=44%
                <br>・全体の裏の手の誤認証の割合:28/50=56%<br>
                <br>という結果となる。
                <br>これらの結果から、照明の有無は機械学習に対して影響があり、学習時とテスト時の画像の環境は
                <br>統一した方がよいということが言える。
            </p>
            <h2 class="title">まとめ</h2>
            <p class="desc">
                私の卒業研究は以上となります。かなり簡略的にまとめましたが、機械学習のノウハウや、認証における
                <br>知見なども得ることが出来ました。将来はプログラマー関連の職に就くかもしれないという曖昧な中で
                <br>あまりプログラムを書かずとも上記のような研究ができたことから、プログラムはあくまでツールに過ぎないのだ
                <br>ということが身をもって知ることが出来ました。
                <br>あまり大した研究ではないですが、私が大学4年時に経験した卒業論文に関する説明は以上となります。
                <br>ここまでご参照いただきありがとうございました。(2022年4月3日)
            </p>
        </div>
        <div class="foottop"><div id="page_top"><a href="#"></a></div></div>
        <script src="script.js"></script>
    </body>
</html>