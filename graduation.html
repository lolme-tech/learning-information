<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Graduation thesis</title>
        <link rel="stylesheet" type="text/css" href="styles/graduation.css">
        <link href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" rel="stylesheet">
        <link rel="graduation" type="text/css" href="”https://lolme-tech.github.io/lerning-information/styles/graduation">
        <script src="//code.jquery.com/jquery-1.12.1.min.js"></script>
    </head>
    <body>
        <div class="header">
            <a href="index.html" class="head">HOME</a>
        </div>
        <div class="body">
            <h1 class="agenda">卒業論文について(2022年3月10日更新)</h1>
            <p class="desc">私の卒業論文の主なテーマは人工知能を用いた手の形状による個人認証に関する研究です。
                <br>個人認証には、指紋認証、顔認証、虹彩認証といった身体的特徴を用いた手法と、パスワードによる記憶認証や歩き方を
                <br>特徴とする歩行認証などの行動的特徴を用いた認証技術があります。
                <br>私の研究では、その中でも手の形状を用いた身体的特徴を用いて認証を行います。
                <br>従来の個人認証では、それぞれ人によって異なる特徴を幾何学的にデータベースに登録し、
                <br>それを照合したスコアによる差分を元に認証を行います。
                <br>しかしながら、私の研究では手の画像を機械学習させることで何が特徴として用いられるかがわからないことが大きく異なります。
                <br>人の手には、指紋や指の大きさ、手のサイズ、それによる影の落とし方など様々な特徴があり、
                <br>それを機械は写真というpx(ピクセル)としてのデータとして分析をします。
            </p>
            <h2 class="title">卒業研究の手順</h2>
            <p class="desc">まず手の画像を機械学習させるには、ある程度数を用意しなければ良い学習を行うことはできません。
                <br>そこで、スマホ用の三脚と間接照明を用意して白い画用紙を敷いた上に配置します。
                <br>白い画用紙に袖をまくった腕を載せて照明を当て、スマホで約5～7秒動画を撮影します。
                <br>こうすることで、PythonのopenCVというライブラリで動画からフレームレートを抽出し、
                <br>大量の画像を簡単に入手することが出来ます。
                <br>5秒間撮影したとしたら、スマホのフレームレートが30なので一人当たり約150枚手に入れることが出来ます。
                <br>動画を撮影する際は、ただ手を置くだけでなく、指を開く、閉じるを交互に繰り返すことで様々な形をした手の画像を入手します。
                <br>機械学習に関しては学び途中であり、本研究もどのような結果になるかわからないため、
                <br>模索しながら最適と感じる方法で準備を行いました。
                <br>手は表の手の平及び裏の手の平を撮影しました。下記に抽出したフレームレートの手の画像を示します。
            <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo12.jpg?raw=true" class="photos">
            <img src="https://github.com/lolme-tech/learning-information/blob/master/photos/photo13.jpg?raw=true" class="photos">
                <br>この一人当たり表の手約150枚と裏の手約150枚の計300枚を沢山の人に協力してもらい画像を収集していきます。
                <br>機械学習には、2014年に画像認識を競う大会でVGGというチームが使用した畳み込みニューラルネットワークというものを用います。
                <br>この機械学習には、8割を学習モデルに、残りの2割を正解モデルとして用います。(正解モデルを用いているので教師あり学習)
                <br>畳み込みニューラルネットワークは畳み込み層とプーリング層に別れ、
                <br>特徴を見つけてそれを圧縮というのを繰り返すモデルになります。
                <br>しかし、本研究ではあくまでも機械学習を用いた個人認証が目的なので、機械学習自体はただのツールとして用いたために
                <br>詳細に原理を理解しているわけではないです。
                <br>機械学習に収集した画像群を与えるために、numpyという二次元処理を簡単に行うPythonのライブラリを用いて、
                <br>ラベル(画像群にラベリング)と画像群の2次元配列にします。
                <br>例えば、ラベル0には自分の表の手の画像群150枚、ラベル1には自分の裏の手の画像群150枚という風に格納されます。
            </p>
        </div>
        <div class="foottop"><div id="page_top"><a href="#"></a></div></div>
        <script src="script.js"></script>
    </body>
</html>